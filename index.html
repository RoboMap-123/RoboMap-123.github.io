<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="MSC-Bench">
  <meta name="keywords" content="MSC-Bench">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RoboMap</title>

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <img 
            src="images/logo.png"
            class="center"
            width="180"
          />
          <h1 class="title is-1 publication-title">
            What Really Matters for Robust Multi-Sensor HD Map Construction?
          </h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Xiaoshuai Hao<sup>1</sup>&nbsp; &nbsp; &nbsp; 
            </span>
            <span class="author-block">
              Lingyu Liu<sup>2</sup>&nbsp; &nbsp; &nbsp; 
            </span>
            <span class="author-block">
              Yuting Zhao<sup>3</sup>&nbsp; &nbsp; &nbsp; 
            </span>
            <span class="author-block">
              Yuheng Ji<sup>3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Luanyuan Dai<sup>4</sup>&nbsp; &nbsp; &nbsp; 
            </span>
            <span class="author-block">
              Peng Hao<sup>5</sup>&nbsp; &nbsp; &nbsp; 
            </span>
            <span class="author-block">
              Dingzhe Li<sup>5</sup>&nbsp; &nbsp; &nbsp; 
            </span>
            <span class="author-block">
              Shuai Cheng<sup>6</sup>&nbsp; &nbsp; &nbsp; 
            </span>
            <span class="author-block">
              Rong Yin<sup>7</sup>&nbsp; &nbsp; &nbsp; 
            </span>
          </div>


          </br>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <sup>1</sup>Beijing Academy of Artificial Intelligence&nbsp;&nbsp;&nbsp; 
              <sup>2</sup>Baidu Inc.&nbsp;&nbsp;&nbsp; 
              <sup>3</sup>Institute of Automation, Chinese Academy of Science&nbsp;&nbsp;&nbsp; 
              <sup>4</sup>Nanjing University of Science and Technology&nbsp;&nbsp;&nbsp; 
              <sup>5</sup>Samsung Research China - Beijing (SRC-B)&nbsp;&nbsp;&nbsp; 
              <sup>6</sup>China North Artificial Intelligent & Innovation Research Institute&nbsp;&nbsp;&nbsp; 
              <sup>7</sup>Institute of Information Engineering, Chinese Academy of Science&nbsp;&nbsp;&nbsp; 
            </span>
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">

              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://robomap-123.github.io/RoboMap.pdf"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://RoboMap-123.github.io"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://RoboMap-123.github.io"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
          <img 
              src="images/framework.png"
              class="pipeline image"
              alt="pipeline image"
              style="margin-bottom: 20px;"
          />
      <h2 class="subtitle has-text-centered">
        This work introduces <strong>RoboMap</strong>, a multi-modal fusion framework for robust HD map construction. 
        We propose three key components: data augmentation, a novel multi-modal fusion module, and a modality dropout training strategy.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            High-definition (HD) map construction methods 
              are crucial for providing precise and comprehensive static 
              environmental information, which is essential for autonomous 
              driving systems. While Camera-LiDAR fusion techniques 
              have shown promising results by integrating data from both 
              modalities, existing approaches primarily focus on improving 
              model accuracy, often neglecting the robustness of perception 
              models—a critical aspect for real-world applications. In this 
              paper, we explore strategies to enhance the robustness of 
              multi-modal fusion methods for HD map construction while 
              maintaining high accuracy. We propose three key components: 
              data augmentation, a novel multi-modal fusion module, and 
              a modality dropout training strategy. These components are 
              evaluated on a challenging dataset containing 13 types of 
              multi-sensor corruption. Experimental results demonstrate that 
              our proposed modules significantly enhance the robustness of 
              baseline methods. Furthermore, our approach achieves state-of-the-art performance on the clean validation set of the 
              NuScenes dataset. Our findings provide valuable insights for 
              developing more robust and reliable HD map construction 
              models, advancing their applicability in real-world autonomous 
driving scenarios.
          </p>
        </div>
      </div>
    </div>

    <hr>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Benchmark Definition</h2>
        <div class="pipeline">
          <img 
              src="images/dataset.png"
              class="pipeline image"
              alt="pipeline image"
          />
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            Overview of the Multi-Sensor Corruption dataset. 
            Multi-Sensor Corruption includes 13 types of synthetic camera-LiDAR corruption combinations 
that perturb both camera and LiDAR inputs, either separately or concurrently. 
          </p>
        </div>
      </div>
    </div>

    <hr>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">RoboMap Overview</h2>
        <div class="pipeline">
        <img 
            src="images/framework.png"
            class="pipeline image"
            alt="pipeline image"
        />
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
        <p>
          Overview of the RoboMap Framework. The RoboMap framework begins by applying data augmentation to both camera images and LiDAR 
point clouds. Next, features are efficiently extracted from the multi-modal sensor inputs and transformed into a unified Bird’s-Eye View (BEV) space using 
view transformation techniques. We then introduce a novel multi-modal BEV fusion module to effectively integrate features from both modalities. Finally, 
the fused BEV features are passed through a shared decoder and prediction heads to generate high-definition (HD) maps.
        </p>
        </div>
      </div>
    </div>

    <hr>

</div>
</div>


</br>
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Robustness Evaluation</h2>
        <div class="pipeline">
        <img 
            src="images/evaluation.png"
            class="pipeline image"
            alt="pipeline image"
        />
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
        <p>
          Comparisons with state-of-the-art methods on NuScenes val set. L and C represent LiDAR and camera, respectively. 
          Effi-B0, R50, PP, and Sec are short for EfficientNet-B0, ResNet50, PointPillars, and SECOND, respectively. 
          Note that RoboMap (MapModel) means our method is integrated into an existing MapModel.
        </p>
        </div>
      </div>
    </div>

    <hr>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="pipeline">
        <img 
            src="images/eval1.jpg"
            class="pipeline image"
            alt="pipeline image"
        />
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
        <p>
          The scores RSc and mRS for the original MapTR model and its variants are presented. RSc uses MAP as the metric.
        </p>
        </div>
      </div>
    </div>
    <hr>

   <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="pipeline">
        <img 
            src="images/eval2.jpg"
            class="pipeline image"
            alt="pipeline image"
        />
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
        <p>
          The scores RSc and mRS for the original HiMap model and its variants are presented. RSc uses MAP as the metric.
        </p>
        </div>
      </div>
    </div>
    <hr>


    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="pipeline">
        <img 
            src="images/eval3.jpg"
            class="pipeline image"
            alt="pipeline image"
        />
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
        <p>
          Analyze the impact of different modules on the HD map construction task using clean data.
        </p>
        </div>
      </div>
    </div>
    <hr>



    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="pipeline">
        <img 
            src="images/eval4.jpg"
            class="pipeline image"
            alt="pipeline image"
        />
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
        <p>
          Relative robustness visualization. Relative Resilience Score (RRS) computed with mAP using original MapTR as baseline.
        </p>
        </div>
      </div>
    </div>
    <hr>


    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="pipeline">
        <img 
            src="images/eval5.jpg"
            class="pipeline image"
            alt="pipeline image"
        />
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
        <p>
          Relative robustness visualization. Relative Resilience Score (RRS) computed with mAP using original HIMap as baseline.
        </p>
        </div>
      </div>
    </div>
    <hr>


</div>
</div>

</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">License</h2>
    <p>The datasets and benchmarks are under the Creative Commons Attribution-NonCommercial-ShareAlike
      4.0 International License</p>
  </div>
</section>

<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{hao2024mapbench,
      title   ={},
      author  ={},
      journal ={arXiv preprint arXiv:},
      year    ={2024}
}
</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="https://homes.cs.washington.edu/~kpar/nerfies/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The source code of this website is borrowed from 
            <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
          <!-- <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/limacv/deblurnerf">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p> -->
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
